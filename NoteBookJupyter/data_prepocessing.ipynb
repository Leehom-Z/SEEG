{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Processes\n",
    "state_dict = {\"sleep\":0, \"preseizure\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys\n",
    "from dtw import dtw\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"../\")\n",
    "from util.util_file import time_add\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.构建滤波数据和原始数据的映射 "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# filter\n",
    "filter_pre_1_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/filter/pre_1\"\n",
    "filter_pre_2_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/filter/pre_2\"\n",
    "filter_sleep_path_dir = \"../visualization_feature/raw_data_time_sequentially/sleep/BDP/filter\"\n",
    "\n",
    "# non-filter\n",
    "non_filter_pre_1_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/no_filter/pre_1\"\n",
    "non_filter_pre_2_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/no_filter/pre_2\"\n",
    "non_filter_sleep_path_dir = \"../visualization_feature/raw_data_time_sequentially/sleep/BDP/no_filter\"\n",
    "\n",
    "# channel list \n",
    "hot_spot_pre_1_path = \"./data/pre_1/BDP_SZ1_pre_seizure_raw.txt\"\n",
    "hot_spot_pre_2_path = \"./data/pre_2/BDP_SZ1_pre_seizure_raw.txt\"\n",
    "hot_spot_sleep_path = \"./data/sleep/BDP_Sleep_raw.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "生成滤波和非滤波切片的映射, 需要提前运行，滤波数据和非滤波数据的路径进行映射"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fi_pre_1:309, fi_pre_2:1783, fi_sleep:7199\n",
      "nfi_pre_1:309, nfi_pre_2:1783, nfi_sleep:7199\n",
      "9291\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fi_pre_1_names = os.listdir(filter_pre_1_path_dir)\n",
    "fi_pre_2_names = os.listdir(filter_pre_2_path_dir)\n",
    "fi_sleep_names = os.listdir(filter_sleep_path_dir)\n",
    "# sorted by time \n",
    "fi_pre_1_names.sort()\n",
    "fi_pre_2_names.sort()\n",
    "fi_sleep_names.sort()\n",
    "print(\"fi_pre_1:{}, fi_pre_2:{}, fi_sleep:{}\".format(len(fi_pre_1_names), len(fi_pre_2_names), len(fi_sleep_names)))\n",
    "\n",
    "nfi_pre_1_names = os.listdir(non_filter_pre_1_path_dir)\n",
    "nfi_pre_2_names = os.listdir(non_filter_pre_2_path_dir)\n",
    "nfi_sleep_names = os.listdir(non_filter_sleep_path_dir)\n",
    "nfi_pre_1_names.sort()\n",
    "nfi_pre_2_names.sort()\n",
    "nfi_sleep_names.sort()\n",
    "print(\"nfi_pre_1:{}, nfi_pre_2:{}, nfi_sleep:{}\".format(len(nfi_pre_1_names), len(nfi_pre_2_names), len(nfi_sleep_names)))\n",
    "\n",
    "\n",
    "fi_nfi_dict = {}\n",
    "label = 1\n",
    "fi_names = [fi_pre_1_names, fi_pre_2_names, fi_sleep_names]\n",
    "nfi_names = [nfi_pre_1_names, nfi_pre_2_names, nfi_sleep_names]\n",
    "nfi_dir = [non_filter_pre_1_path_dir, non_filter_pre_2_path_dir, non_filter_sleep_path_dir]\n",
    "for _index, fi_ida in enumerate(fi_names):\n",
    "    _nfi_d = nfi_dir[_index]\n",
    "    nfi_ida = nfi_names[_index]\n",
    "    label = 1 if _index < 2 else 0\n",
    "    for fi_n, nfi_n in zip(fi_ida, nfi_ida):\n",
    "        nfi_ab_path = os.path.join(_nfi_d, nfi_n)\n",
    "        fi_nfi_dict[fi_n] = {\"nfi_path\":nfi_ab_path, \"label\": label}\n",
    "        \n",
    "print(len(fi_nfi_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "将映射表进行保存\n",
    "\n",
    "保存格式：{fi_id:{\"nfi_id\":nfi_id, \"label\":0/1 }}\n",
    "\n",
    "fi_id: 经过滤波切片的id，  nfi_if: 没有经过滤波的切片id\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "映射表保存成功！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sava_file = \"./data/fi_nfi_id.pkl\"\n",
    "with open(sava_file, 'wb') as f:\n",
    "    pickle.dump(fi_nfi_dict, f)\n",
    "    print(\"映射表保存成功！\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.特征重新映射,需要将特征和id序列号进行映射"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(309, 50) (1783, 50) (7199, 50)\n",
      "(9291, 50)\n",
      "9291\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "feature_pre_1_path = \"./data/pre_1/BDP-feature.npy\"\n",
    "feature_pre_2_path = \"./data/pre_2/BDP-feature.npy\"\n",
    "feature_sleep_path = \"./data/sleep/BDP-feature.npy\"\n",
    "\n",
    "feature_pre_1_data = np.load(feature_pre_1_path)\n",
    "feature_pre_2_data = np.load(feature_pre_2_path)\n",
    "feature_sleep_data = np.load(feature_sleep_path)\n",
    "\n",
    "print(feature_pre_1_data.shape, feature_pre_2_data.shape, feature_sleep_data.shape)\n",
    "feature_id_data_dict = {}\n",
    "concatenate_feature = np.concatenate((feature_pre_1_data, feature_pre_2_data, feature_sleep_data), axis=0)\n",
    "print(concatenate_feature.shape)\n",
    "for id, data in zip(fi_pre_1_names+fi_pre_2_names+fi_sleep_names, concatenate_feature):\n",
    "    feature_id_data_dict[id] = data\n",
    "print(len(feature_id_data_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "特征id序列化完成！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "save_path = \"./data/feature_id_data_dict.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_id_data_dict, f)\n",
    "    print(\"特征id序列化完成！\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.选出模型判定正确的特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "9074\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "path_val_prediction = \"./data/BDP_val_prediction.pkl\"\n",
    "val_prediction_dict = np.load(path_val_prediction, allow_pickle=True)\n",
    "print(len(val_prediction_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "4224\n",
      "不存在的id数：217\n",
      "模型写入成功！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "feature_true_id_prediction = {}\n",
    "count = 0\n",
    "for id, data in feature_id_data_dict.items():\n",
    "    if id in val_prediction_dict.keys():\n",
    "        if val_prediction_dict[id][\"ground truth\"] == val_prediction_dict[id][\"prediction\"]:\n",
    "            feature_true_id_prediction[id] = data\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "print(len(feature_true_id_prediction))\n",
    "print(\"不存在的id数：{}\".format(count))\n",
    "\n",
    "# 选择特征的写回\n",
    "save_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_true_id_prediction, f)\n",
    "    print(\"模型写入成功！\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 每个特征和时间的映射关系"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "9291\n",
      "特征时间映射完成！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "feature_id_time_dict = {}\n",
    "pre_1_time = (23, 1, 52)\n",
    "pre_2_time = (3, 1, 52)\n",
    "sleep_time = (23, 1, 52)\n",
    "_time = pre_1_time\n",
    "for id in fi_pre_1_names:\n",
    "    feature_id_time_dict[id] = _time\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "_time = pre_2_time\n",
    "for id in fi_pre_2_names:\n",
    "    feature_id_time_dict[id] = _time\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "_time = sleep_time\n",
    "for id in fi_sleep_names:\n",
    "    feature_id_time_dict[id] = _time\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "save_path = \"./data/feature_id_time_dict.pkl\"\n",
    "print(len(feature_id_time_dict))\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_id_time_dict, f)\n",
    "    print(\"特征时间映射完成！\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 将特征和特征选取的信道进行映射{feature_id:channel_No}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "3it [00:00, 25.77it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "id 热点信息映射完成！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "hot_spot_pre_1_list = pd.read_csv(hot_spot_pre_1_path, sep=',')\n",
    "hot_spot_pre_2_list = pd.read_csv(hot_spot_pre_2_path, sep=',')\n",
    "hot_spot_sleep_list = pd.read_csv(hot_spot_sleep_path, sep=',')\n",
    "feature_id_time_spatial= {}\n",
    "run_list = [hot_spot_pre_1_list, hot_spot_pre_2_list, hot_spot_sleep_list]\n",
    "run_list_dict = [fi_pre_1_names, fi_pre_2_names, fi_sleep_names]\n",
    "for _index, r in tqdm(enumerate(run_list)):\n",
    "    _time = r[\"time_location\"]\n",
    "    _spatial = r[\"spatial_location\"] \n",
    "    fi_names = run_list_dict[_index]\n",
    "    for i, id_name  in enumerate(fi_names):\n",
    "        _time_line = _time[i].split(\"-\")[0]\n",
    "        _spatial_line = _spatial[i].split(\"-\")[0]\n",
    "        record_line = {\"time\":int(_time_line), \"spatial\":int(_spatial_line)}\n",
    "        feature_id_time_spatial[id_name] = record_line\n",
    "\n",
    "with open(\"./data/feature_id_time_spatial.pkl\", 'wb') as f:\n",
    "    pickle.dump(feature_id_time_spatial, f)\n",
    "    print(\"id 热点信息映射完成！\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.计算特征之间的相似度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "./data/feature_true_id_prediction.pkl 读取成功！, 数据长度:4224\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "read_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "with open(read_path, 'rb') as f:\n",
    "    feature_true_id_prediction = pickle.load(f)\n",
    "    print(\"{} 读取成功！, 数据长度:{}\".format(read_path, len(feature_true_id_prediction)))\n",
    "#print(len(feature_true_id_prediction))\n",
    "def similarity_DTW(s1, s2):\n",
    "    ratio = 50 # 设定的放缩系数，避免数据的相似度过于集中\n",
    "    euclidean_norm = lambda x, y: np.abs(ratio * (x - y))\n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(s1, s2, dist=euclidean_norm)\n",
    "    score = 1 - np.tanh(d)  # 相似度的评分【0,1】 0： 完全不同， 1： 完全相同\n",
    "    return score\n",
    "score_similarity_DTW = np.zeros((len(feature_true_id_prediction), len(feature_true_id_prediction)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 4224/4224 [17:58:30<00:00, 15.32s/it]  \n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "[[1.         0.50805205 0.57154351 ... 0.53064618 0.55182377 0.53249634]\n",
      " [0.50805205 1.         0.88322358 ... 0.89614757 0.88409826 0.95944175]\n",
      " [0.57154351 0.88322358 1.         ... 0.85162603 0.85760652 0.85375908]\n",
      " ...\n",
      " [0.53064618 0.89614757 0.85162603 ... 1.         0.90773485 0.91012109]\n",
      " [0.55182377 0.88409826 0.85760652 ... 0.90773485 1.         0.86551955]\n",
      " [0.53249634 0.95944175 0.85375908 ... 0.91012109 0.86551955 1.        ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "id_list = list(feature_true_id_prediction.keys())\n",
    "for i, id in enumerate(tqdm(id_list)):\n",
    "    s1 = feature_true_id_prediction[id]\n",
    "    for j in range(0, i+1):\n",
    "        id_2 = id_list[j]\n",
    "        s2 = feature_true_id_prediction[id_2]\n",
    "        score = similarity_DTW(s1, s2)\n",
    "        score_similarity_DTW[i][j] = score\n",
    "        score_similarity_DTW[j][i] = score\n",
    "print(score_similarity_DTW)\n",
    "save_DTW_data = \"./processing/DTW_similarity_matrix.npy\"\n",
    "np.save(save_DTW_data, score_similarity_DTW)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(4224, 4224)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(score_similarity_DTW.shape)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ching",
   "language": "python",
   "display_name": "ching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}