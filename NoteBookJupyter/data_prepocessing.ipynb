{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Processes\n",
    "state_dict = {\"sleep\":0, \"preseizure\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:02.298227Z",
     "start_time": "2020-01-14T18:29:01.620976Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys\n",
    "from dtw import dtw\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(\"../\")\n",
    "from util.util_file import time_add\n",
    "import pandas as pd\n",
    "print(\"Start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.构建滤波数据和原始数据的映射 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:04.326339Z",
     "start_time": "2020-01-14T18:29:04.323770Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# filter\n",
    "filter_pre_1_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/filter/pre_1\"\n",
    "filter_pre_2_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/filter/pre_2\"\n",
    "filter_sleep_path_dir = \"../visualization_feature/raw_data_time_sequentially/sleep/BDP/filter\"\n",
    "\n",
    "# non-filter\n",
    "non_filter_pre_1_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/no_filter/pre_1\"\n",
    "non_filter_pre_2_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/no_filter/pre_2\"\n",
    "non_filter_sleep_path_dir = \"../visualization_feature/raw_data_time_sequentially/sleep/BDP/no_filter\"\n",
    "\n",
    "# channel list \n",
    "hot_spot_pre_1_path = \"./data/pre_1/BDP_SZ1_pre_seizure_raw.txt\"\n",
    "hot_spot_pre_2_path = \"./data/pre_2/BDP_SZ1_pre_seizure_raw.txt\"\n",
    "hot_spot_sleep_path = \"./data/sleep/BDP_Sleep_raw.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成滤波和非滤波切片的映射, 需要提前运行，滤波数据和非滤波数据的路径进行映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:06.654203Z",
     "start_time": "2020-01-14T18:29:06.627274Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fi_pre_1:309, fi_pre_2:1783, fi_sleep:7199\n",
      "nfi_pre_1:309, nfi_pre_2:1783, nfi_sleep:7199\n",
      "9291\n"
     ]
    }
   ],
   "source": [
    "fi_pre_1_names = os.listdir(filter_pre_1_path_dir)\n",
    "fi_pre_2_names = os.listdir(filter_pre_2_path_dir)\n",
    "fi_sleep_names = os.listdir(filter_sleep_path_dir)\n",
    "# sorted by time \n",
    "fi_pre_1_names.sort()\n",
    "fi_pre_2_names.sort()\n",
    "fi_sleep_names.sort()\n",
    "print(\"fi_pre_1:{}, fi_pre_2:{}, fi_sleep:{}\".format(len(fi_pre_1_names), len(fi_pre_2_names), len(fi_sleep_names)))\n",
    "\n",
    "nfi_pre_1_names = os.listdir(non_filter_pre_1_path_dir)\n",
    "nfi_pre_2_names = os.listdir(non_filter_pre_2_path_dir)\n",
    "nfi_sleep_names = os.listdir(non_filter_sleep_path_dir)\n",
    "nfi_pre_1_names.sort()\n",
    "nfi_pre_2_names.sort()\n",
    "nfi_sleep_names.sort()\n",
    "print(\"nfi_pre_1:{}, nfi_pre_2:{}, nfi_sleep:{}\".format(len(nfi_pre_1_names), len(nfi_pre_2_names), len(nfi_sleep_names)))\n",
    "\n",
    "\n",
    "fi_nfi_dict = {}\n",
    "label = 1\n",
    "fi_names = [fi_pre_1_names, fi_pre_2_names, fi_sleep_names]\n",
    "nfi_names = [nfi_pre_1_names, nfi_pre_2_names, nfi_sleep_names]\n",
    "nfi_dir = [non_filter_pre_1_path_dir, non_filter_pre_2_path_dir, non_filter_sleep_path_dir]\n",
    "for _index, fi_ida in enumerate(fi_names):\n",
    "    _nfi_d = nfi_dir[_index]\n",
    "    nfi_ida = nfi_names[_index]\n",
    "    label = 1 if _index < 2 else 0\n",
    "    for fi_n, nfi_n in zip(fi_ida, nfi_ida):\n",
    "        nfi_ab_path = os.path.join(_nfi_d, nfi_n)\n",
    "        fi_nfi_dict[fi_n] = {\"nfi_path\":nfi_ab_path, \"label\": label}\n",
    "        \n",
    "print(len(fi_nfi_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "将映射表进行保存\n",
    "\n",
    "保存格式：{fi_id:{\"nfi_id\":nfi_id, \"label\":0/1 }}\n",
    "\n",
    "fi_id: 经过滤波切片的id，  nfi_if: 没有经过滤波的切片id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:08.976129Z",
     "start_time": "2020-01-14T18:29:08.968653Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "映射表保存成功！\n"
     ]
    }
   ],
   "source": [
    "sava_file = \"./data/fi_nfi_id.pkl\"\n",
    "with open(sava_file, 'wb') as f:\n",
    "    pickle.dump(fi_nfi_dict, f)\n",
    "    print(\"映射表保存成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.特征重新映射,需要将特征和id序列号进行映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:10.437931Z",
     "start_time": "2020-01-14T18:29:10.418463Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 50) (1783, 50) (7199, 50)\n",
      "(9291, 50)\n",
      "9291\n"
     ]
    }
   ],
   "source": [
    "feature_pre_1_path = \"./data/pre_1/BDP-feature.npy\"\n",
    "feature_pre_2_path = \"./data/pre_2/BDP-feature.npy\"\n",
    "feature_sleep_path = \"./data/sleep/BDP-feature.npy\"\n",
    "\n",
    "feature_pre_1_data = np.load(feature_pre_1_path)\n",
    "feature_pre_2_data = np.load(feature_pre_2_path)\n",
    "feature_sleep_data = np.load(feature_sleep_path)\n",
    "\n",
    "print(feature_pre_1_data.shape, feature_pre_2_data.shape, feature_sleep_data.shape)\n",
    "feature_id_data_dict = {}\n",
    "concatenate_feature = np.concatenate((feature_pre_1_data, feature_pre_2_data, feature_sleep_data), axis=0)\n",
    "print(concatenate_feature.shape)\n",
    "for id, data in zip(fi_pre_1_names+fi_pre_2_names+fi_sleep_names, concatenate_feature):\n",
    "    feature_id_data_dict[id] = data\n",
    "print(len(feature_id_data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:12.904477Z",
     "start_time": "2020-01-14T18:29:12.850833Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征id序列化完成！\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./data/feature_id_data_dict.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_id_data_dict, f)\n",
    "    print(\"特征id序列化完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.选出模型判定正确的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:14.585617Z",
     "start_time": "2020-01-14T18:29:14.580153Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9074\n"
     ]
    }
   ],
   "source": [
    "path_val_prediction = \"./data/BDP_val_prediction.pkl\"\n",
    "val_prediction_dict = np.load(path_val_prediction, allow_pickle=True)\n",
    "print(len(val_prediction_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:15.672154Z",
     "start_time": "2020-01-14T18:29:15.652861Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4224\n",
      "不存在的id数：217\n",
      "模型写入成功！\n"
     ]
    }
   ],
   "source": [
    "feature_true_id_prediction = {}\n",
    "count = 0\n",
    "for id, data in feature_id_data_dict.items():\n",
    "    if id in val_prediction_dict.keys():\n",
    "        if val_prediction_dict[id][\"ground truth\"] == val_prediction_dict[id][\"prediction\"]:\n",
    "            feature_true_id_prediction[id] = data\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "print(len(feature_true_id_prediction))\n",
    "print(\"不存在的id数：{}\".format(count))\n",
    "\n",
    "# 选择特征的写回\n",
    "save_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_true_id_prediction, f)\n",
    "    print(\"模型写入成功！\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. 每个特征和时间的映射关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:18.958126Z",
     "start_time": "2020-01-14T18:29:18.937077Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9291\n",
      "特征时间映射完成！\n"
     ]
    }
   ],
   "source": [
    "feature_id_time_dict = {}\n",
    "pre_1_time = (23, 1, 52)\n",
    "file_name_1 = \"pre_seizure_1\"\n",
    "pre_2_time = (3, 1, 52)\n",
    "file_name_2 = \"pre_seizure_2\"\n",
    "sleep_time = (23, 1, 52)\n",
    "file_name_3 = \"normal_sleep\"\n",
    "_time = pre_1_time\n",
    "Relative_Time = (0, 0, 0)\n",
    "for id in fi_pre_1_names:\n",
    "    feature_id_time_dict[id] = {\"Absolute time\":_time, \"Relative time\": Relative_Time, \"File name\":file_name_1}\n",
    "    Relative_Time = time_add(Relative_Time[0], Relative_Time[1], Relative_Time[2], 2)\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "_time = pre_2_time\n",
    "Relative_Time = (0, 0, 0)\n",
    "for id in fi_pre_2_names:\n",
    "    feature_id_time_dict[id] = {\"Absolute time\":_time, \"Relative time\": Relative_Time, \"File name\":file_name_2}\n",
    "    Relative_Time = time_add(Relative_Time[0], Relative_Time[1], Relative_Time[2], 2)\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "_time = sleep_time\n",
    "Relative_Time = (0, 0, 0)\n",
    "for id in fi_sleep_names:\n",
    "    feature_id_time_dict[id] = {\"Absolute time\":_time, \"Relative time\": Relative_Time, \"File name\":file_name_3}\n",
    "    Relative_Time = time_add(Relative_Time[0], Relative_Time[1], Relative_Time[2], 2)\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "save_path = \"./data/feature_id_time_dict.pkl\"\n",
    "print(len(feature_id_time_dict))\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_id_time_dict, f)\n",
    "    print(\"特征时间映射完成！\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. 将特征和特征选取的信道进行映射{feature_id:channel_No}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:20.255186Z",
     "start_time": "2020-01-14T18:29:20.107756Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcf5c98c70047bc8f204f0dfc675310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "id 热点信息映射完成！\n"
     ]
    }
   ],
   "source": [
    "hot_spot_pre_1_list = pd.read_csv(hot_spot_pre_1_path, sep=',')\n",
    "hot_spot_pre_2_list = pd.read_csv(hot_spot_pre_2_path, sep=',')\n",
    "hot_spot_sleep_list = pd.read_csv(hot_spot_sleep_path, sep=',')\n",
    "feature_id_time_spatial= {}\n",
    "run_list = [hot_spot_pre_1_list, hot_spot_pre_2_list, hot_spot_sleep_list]\n",
    "run_list_dict = [fi_pre_1_names, fi_pre_2_names, fi_sleep_names]\n",
    "for _index, r in tqdm(enumerate(run_list)):\n",
    "    _time = r[\"time_location\"]\n",
    "    _spatial = r[\"spatial_location\"] \n",
    "    fi_names = run_list_dict[_index]\n",
    "    for i, id_name  in enumerate(fi_names):\n",
    "        _time_line = _time[i].split(\"-\")[0]\n",
    "        _spatial_line = _spatial[i].split(\"-\")[0]\n",
    "        record_line = {\"time\":int(_time_line), \"spatial\":int(_spatial_line)}\n",
    "        feature_id_time_spatial[id_name] = record_line\n",
    "\n",
    "with open(\"./data/feature_id_time_spatial.pkl\", 'wb') as f:\n",
    "    pickle.dump(feature_id_time_spatial, f)\n",
    "    print(\"id 热点信息映射完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6.计算特征之间的distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T18:29:30.141974Z",
     "start_time": "2020-01-14T18:29:30.132263Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/feature_true_id_prediction.pkl 读取成功！, 数据长度:4224\n"
     ]
    }
   ],
   "source": [
    "read_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "with open(read_path, 'rb') as f:\n",
    "    feature_true_id_prediction = pickle.load(f)\n",
    "    print(\"{} 读取成功！, 数据长度:{}\".format(read_path, len(feature_true_id_prediction)))\n",
    "#print(len(feature_true_id_prediction))\n",
    "def similarity_DTW(s1, s2):\n",
    "    ratio = 1 # 设定的放缩系数，避免数据的相似度过于集中\n",
    "    euclidean_norm = lambda x, y: np.abs(ratio * (x - y))\n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(s1, s2, dist=euclidean_norm)\n",
    "    # score = 1 - np.tanh(d)  # 相似度的评分【0,1】 0： 完全不同， 1： 完全相同\n",
    "    return d\n",
    "score_similarity_DTW = np.zeros((len(feature_true_id_prediction), len(feature_true_id_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T12:39:21.682895Z",
     "start_time": "2020-01-14T18:29:37.566974Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407870d5399448c492cb3ea31d1cc748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4224.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.         0.01438541 0.02431704 ... 0.02458381 0.02068662 0.02572145]\n",
      " [0.01438541 0.         0.01598483 ... 0.00420379 0.00311675 0.00466537]\n",
      " [0.02431704 0.01598483 0.         ... 0.01647419 0.01543484 0.01856046]\n",
      " ...\n",
      " [0.02458381 0.00420379 0.01647419 ... 0.         0.00185057 0.00180244]\n",
      " [0.02068662 0.00311675 0.01543484 ... 0.00185057 0.         0.002706  ]\n",
      " [0.02572145 0.00466537 0.01856046 ... 0.00180244 0.002706   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "id_list = list(feature_true_id_prediction.keys())\n",
    "for i, id in enumerate(tqdm(id_list)):\n",
    "    s1 = feature_true_id_prediction[id]\n",
    "    for j in range(0, i+1):\n",
    "        id_2 = id_list[j]\n",
    "        s2 = feature_true_id_prediction[id_2]\n",
    "        score = similarity_DTW(s1, s2)\n",
    "        score_similarity_DTW[i][j] = score\n",
    "        score_similarity_DTW[j][i] = score\n",
    "print(score_similarity_DTW)\n",
    "save_DTW_data = \"./processing/DTW_similarity_matrix.npy\"\n",
    "np.save(save_DTW_data, score_similarity_DTW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 7. 可选模块的运行分析-（主要是针对于优化过后的cluster在进行一聚类分析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# cluster:8 ID:1\n",
    "Best_label_cluster_path = \"./processing/Best_label_cluster.pkl\"\n",
    "DTW_distance_matrix_path = \"./processing/DTW_distance_matrix.npy\"\n",
    "Best_label_cluster = np.load(Best_label_cluster_path, allow_pickle=True)\n",
    "print(len(Best_label_cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DTW_distance_matrix = np.load(DTW_distance_matrix_path)\n",
    "Cluster_8_ID_1 = Best_label_cluster[1]\n",
    "print(len(Cluster_8_ID_1))\n",
    "print(DTW_distance_matrix.shape)\n",
    "feature_true_id_prediction_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "feature_true_id_prediction = np.load(feature_true_id_prediction_path, allow_pickle=True)\n",
    "fi_name_list = list(feature_true_id_prediction.keys())\n",
    "print(len(fi_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Cluster_8_ID_distance = np.zeros((len(Cluster_8_ID_1), len(Cluster_8_ID_1)))\n",
    "for i, f_id_a in tqdm(enumerate(Cluster_8_ID_1)):\n",
    "    for j in range(i+1):\n",
    "        f_id_b = Cluster_8_ID_1[j]\n",
    "        index_a = fi_name_list.index(f_id_a)\n",
    "        index_b = fi_name_list.index(f_id_b)\n",
    "        score = DTW_distance_matrix[index_a, index_b]\n",
    "        Cluster_8_ID_distance[i][j] = score\n",
    "        Cluster_8_ID_distance[j][i] = score\n",
    "Cluster_8_ID_1_result = {\"fi_id_list\":Cluster_8_ID_1,\n",
    "                         \"DTW_distance_matrix\":Cluster_8_ID_distance\n",
    "                         }\n",
    "save_path = \"./processing/Cluster_8_ID_1__fid_list_distance.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(Cluster_8_ID_1_result, f)\n",
    "    print(\"文件写入成功！cluster_8_id_1_result\")\n",
    "\n",
    "save_path = \"./processing/feature_true_id_prediction_cluster_8_1.pkl\"\n",
    "feature_true_id_prediction_cluster_8_1 = {}\n",
    "for f_id in Cluster_8_ID_1:\n",
    "    feature_true_id_prediction_cluster_8_1[f_id] = feature_true_id_prediction[f_id]\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_true_id_prediction_cluster_8_1, f)\n",
    "    print(\"特定feature 写入成功！\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(score_similarity_DTW.shape)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ching",
   "language": "python",
   "name": "ching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "ctrl-shift-e"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
