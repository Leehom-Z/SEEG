{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Processes\n",
    "state_dict = {\"sleep\":0, \"preseizure\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pickle\n",
    "import sys\n",
    "from dtw import dtw\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(\"../\")\n",
    "from util.util_file import time_add\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.构建滤波数据和原始数据的映射 "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# filter\n",
    "filter_pre_1_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/filter/pre_1\"\n",
    "filter_pre_2_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/filter/pre_2\"\n",
    "filter_sleep_path_dir = \"../visualization_feature/raw_data_time_sequentially/sleep/BDP/filter\"\n",
    "\n",
    "# non-filter\n",
    "non_filter_pre_1_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/no_filter/pre_1\"\n",
    "non_filter_pre_2_path_dir = \"../visualization_feature/raw_data_time_sequentially/preseizure/BDP/no_filter/pre_2\"\n",
    "non_filter_sleep_path_dir = \"../visualization_feature/raw_data_time_sequentially/sleep/BDP/no_filter\"\n",
    "\n",
    "# channel list \n",
    "hot_spot_pre_1_path = \"./data/pre_1/BDP_SZ1_pre_seizure_raw.txt\"\n",
    "hot_spot_pre_2_path = \"./data/pre_2/BDP_SZ1_pre_seizure_raw.txt\"\n",
    "hot_spot_sleep_path = \"./data/sleep/BDP_Sleep_raw.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "生成滤波和非滤波切片的映射, 需要提前运行，滤波数据和非滤波数据的路径进行映射"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fi_pre_1:309, fi_pre_2:1783, fi_sleep:7199\n",
      "nfi_pre_1:309, nfi_pre_2:1783, nfi_sleep:7199\n",
      "9291\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "fi_pre_1_names = os.listdir(filter_pre_1_path_dir)\n",
    "fi_pre_2_names = os.listdir(filter_pre_2_path_dir)\n",
    "fi_sleep_names = os.listdir(filter_sleep_path_dir)\n",
    "# sorted by time \n",
    "fi_pre_1_names.sort()\n",
    "fi_pre_2_names.sort()\n",
    "fi_sleep_names.sort()\n",
    "print(\"fi_pre_1:{}, fi_pre_2:{}, fi_sleep:{}\".format(len(fi_pre_1_names), len(fi_pre_2_names), len(fi_sleep_names)))\n",
    "\n",
    "nfi_pre_1_names = os.listdir(non_filter_pre_1_path_dir)\n",
    "nfi_pre_2_names = os.listdir(non_filter_pre_2_path_dir)\n",
    "nfi_sleep_names = os.listdir(non_filter_sleep_path_dir)\n",
    "nfi_pre_1_names.sort()\n",
    "nfi_pre_2_names.sort()\n",
    "nfi_sleep_names.sort()\n",
    "print(\"nfi_pre_1:{}, nfi_pre_2:{}, nfi_sleep:{}\".format(len(nfi_pre_1_names), len(nfi_pre_2_names), len(nfi_sleep_names)))\n",
    "\n",
    "\n",
    "fi_nfi_dict = {}\n",
    "label = 1\n",
    "fi_names = [fi_pre_1_names, fi_pre_2_names, fi_sleep_names]\n",
    "nfi_names = [nfi_pre_1_names, nfi_pre_2_names, nfi_sleep_names]\n",
    "nfi_dir = [non_filter_pre_1_path_dir, non_filter_pre_2_path_dir, non_filter_sleep_path_dir]\n",
    "for _index, fi_ida in enumerate(fi_names):\n",
    "    _nfi_d = nfi_dir[_index]\n",
    "    nfi_ida = nfi_names[_index]\n",
    "    label = 1 if _index < 2 else 0\n",
    "    for fi_n, nfi_n in zip(fi_ida, nfi_ida):\n",
    "        nfi_ab_path = os.path.join(_nfi_d, nfi_n)\n",
    "        fi_nfi_dict[fi_n] = {\"nfi_path\":nfi_ab_path, \"label\": label}\n",
    "        \n",
    "print(len(fi_nfi_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "将映射表进行保存\n",
    "\n",
    "保存格式：{fi_id:{\"nfi_id\":nfi_id, \"label\":0/1 }}\n",
    "\n",
    "fi_id: 经过滤波切片的id，  nfi_if: 没有经过滤波的切片id\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "映射表保存成功！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sava_file = \"./data/fi_nfi_id.pkl\"\n",
    "with open(sava_file, 'wb') as f:\n",
    "    pickle.dump(fi_nfi_dict, f)\n",
    "    print(\"映射表保存成功！\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.特征重新映射,需要将特征和id序列号进行映射"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(309, 50) (1783, 50) (7199, 50)\n",
      "(9291, 50)\n",
      "9291\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "feature_pre_1_path = \"./data/pre_1/BDP-feature.npy\"\n",
    "feature_pre_2_path = \"./data/pre_2/BDP-feature.npy\"\n",
    "feature_sleep_path = \"./data/sleep/BDP-feature.npy\"\n",
    "\n",
    "feature_pre_1_data = np.load(feature_pre_1_path)\n",
    "feature_pre_2_data = np.load(feature_pre_2_path)\n",
    "feature_sleep_data = np.load(feature_sleep_path)\n",
    "\n",
    "print(feature_pre_1_data.shape, feature_pre_2_data.shape, feature_sleep_data.shape)\n",
    "feature_id_data_dict = {}\n",
    "concatenate_feature = np.concatenate((feature_pre_1_data, feature_pre_2_data, feature_sleep_data), axis=0)\n",
    "print(concatenate_feature.shape)\n",
    "for id, data in zip(fi_pre_1_names+fi_pre_2_names+fi_sleep_names, concatenate_feature):\n",
    "    feature_id_data_dict[id] = data\n",
    "print(len(feature_id_data_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "特征id序列化完成！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "save_path = \"./data/feature_id_data_dict.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_id_data_dict, f)\n",
    "    print(\"特征id序列化完成！\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.选出模型判定正确的特征"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "9074\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "path_val_prediction = \"./data/BDP_val_prediction.pkl\"\n",
    "val_prediction_dict = np.load(path_val_prediction, allow_pickle=True)\n",
    "print(len(val_prediction_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "4224\n",
      "不存在的id数：217\n",
      "模型写入成功！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "feature_true_id_prediction = {}\n",
    "count = 0\n",
    "for id, data in feature_id_data_dict.items():\n",
    "    if id in val_prediction_dict.keys():\n",
    "        if val_prediction_dict[id][\"ground truth\"] == val_prediction_dict[id][\"prediction\"]:\n",
    "            feature_true_id_prediction[id] = data\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "print(len(feature_true_id_prediction))\n",
    "print(\"不存在的id数：{}\".format(count))\n",
    "\n",
    "# 选择特征的写回\n",
    "save_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_true_id_prediction, f)\n",
    "    print(\"模型写入成功！\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 每个特征和时间的映射关系"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "9291\n",
      "特征时间映射完成！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "feature_id_time_dict = {}\n",
    "pre_1_time = (23, 1, 52)\n",
    "file_name_1 = \"pre_seizure_1\"\n",
    "pre_2_time = (3, 1, 52)\n",
    "file_name_2 = \"pre_seizure_2\"\n",
    "sleep_time = (23, 1, 52)\n",
    "file_name_3 = \"normal_sleep\"\n",
    "_time = pre_1_time\n",
    "Relative_Time = (0, 0, 0)\n",
    "for id in fi_pre_1_names:\n",
    "    feature_id_time_dict[id] = {\"Absolute time\":_time, \"Relative time\": Relative_Time, \"File name\":file_name_1}\n",
    "    Relative_Time = time_add(Relative_Time[0], Relative_Time[1], Relative_Time[2], 2)\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "_time = pre_2_time\n",
    "Relative_Time = (0, 0, 0)\n",
    "for id in fi_pre_2_names:\n",
    "    feature_id_time_dict[id] = {\"Absolute time\":_time, \"Relative time\": Relative_Time, \"File name\":file_name_2}\n",
    "    Relative_Time = time_add(Relative_Time[0], Relative_Time[1], Relative_Time[2], 2)\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "_time = sleep_time\n",
    "Relative_Time = (0, 0, 0)\n",
    "for id in fi_sleep_names:\n",
    "    feature_id_time_dict[id] = {\"Absolute time\":_time, \"Relative time\": Relative_Time, \"File name\":file_name_3}\n",
    "    Relative_Time = time_add(Relative_Time[0], Relative_Time[1], Relative_Time[2], 2)\n",
    "    _time = time_add(_time[0], _time[1], _time[2], 2)\n",
    "\n",
    "save_path = \"./data/feature_id_time_dict.pkl\"\n",
    "print(len(feature_id_time_dict))\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_id_time_dict, f)\n",
    "    print(\"特征时间映射完成！\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 将特征和特征选取的信道进行映射{feature_id:channel_No}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e54cec1efeb4bc3ae1ba827cca435f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\n",
      "id 热点信息映射完成！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "hot_spot_pre_1_list = pd.read_csv(hot_spot_pre_1_path, sep=',')\n",
    "hot_spot_pre_2_list = pd.read_csv(hot_spot_pre_2_path, sep=',')\n",
    "hot_spot_sleep_list = pd.read_csv(hot_spot_sleep_path, sep=',')\n",
    "feature_id_time_spatial= {}\n",
    "run_list = [hot_spot_pre_1_list, hot_spot_pre_2_list, hot_spot_sleep_list]\n",
    "run_list_dict = [fi_pre_1_names, fi_pre_2_names, fi_sleep_names]\n",
    "for _index, r in tqdm(enumerate(run_list)):\n",
    "    _time = r[\"time_location\"]\n",
    "    _spatial = r[\"spatial_location\"] \n",
    "    fi_names = run_list_dict[_index]\n",
    "    for i, id_name  in enumerate(fi_names):\n",
    "        _time_line = _time[i].split(\"-\")[0]\n",
    "        _spatial_line = _spatial[i].split(\"-\")[0]\n",
    "        record_line = {\"time\":int(_time_line), \"spatial\":int(_spatial_line)}\n",
    "        feature_id_time_spatial[id_name] = record_line\n",
    "\n",
    "with open(\"./data/feature_id_time_spatial.pkl\", 'wb') as f:\n",
    "    pickle.dump(feature_id_time_spatial, f)\n",
    "    print(\"id 热点信息映射完成！\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.计算特征之间的distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "./data/feature_true_id_prediction.pkl 读取成功！, 数据长度:4224\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "read_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "with open(read_path, 'rb') as f:\n",
    "    feature_true_id_prediction = pickle.load(f)\n",
    "    print(\"{} 读取成功！, 数据长度:{}\".format(read_path, len(feature_true_id_prediction)))\n",
    "#print(len(feature_true_id_prediction))\n",
    "def similarity_DTW(s1, s2):\n",
    "    ratio = 1 # 设定的放缩系数，避免数据的相似度过于集中\n",
    "    euclidean_norm = lambda x, y: np.abs(ratio * (x - y))\n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(s1, s2, dist=euclidean_norm)\n",
    "    # score = 1 - np.tanh(d)  # 相似度的评分【0,1】 0： 完全不同， 1： 完全相同\n",
    "    return d\n",
    "score_similarity_DTW = np.zeros((len(feature_true_id_prediction), len(feature_true_id_prediction)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=4224.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e840ccf2b43b4f66a98616741922710a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-4a2a9b1bcf9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mid_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_true_id_prediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity_DTW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mscore_similarity_DTW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mscore_similarity_DTW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarity_DTW' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'similarity_DTW' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "id_list = list(feature_true_id_prediction.keys())\n",
    "for i, id in enumerate(tqdm(id_list)):\n",
    "    s1 = feature_true_id_prediction[id]\n",
    "    for j in range(0, i+1):\n",
    "        id_2 = id_list[j]\n",
    "        s2 = feature_true_id_prediction[id_2]\n",
    "        score = similarity_DTW(s1, s2)\n",
    "        score_similarity_DTW[i][j] = score\n",
    "        score_similarity_DTW[j][i] = score\n",
    "print(score_similarity_DTW)\n",
    "save_DTW_data = \"./processing/DTW_similarity_matrix.npy\"\n",
    "np.save(save_DTW_data, score_similarity_DTW)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. 可选模块的运行分析-（主要是针对于优化过后的cluster在进行一聚类分析）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "8\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# cluster:8 ID:1\n",
    "Best_label_cluster_path = \"./processing/Best_label_cluster.pkl\"\n",
    "DTW_distance_matrix_path = \"./processing/DTW_distance_matrix.npy\"\n",
    "Best_label_cluster = np.load(Best_label_cluster_path, allow_pickle=True)\n",
    "print(len(Best_label_cluster))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1215\n",
      "(4224, 4224)\n",
      "4224\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "DTW_distance_matrix = np.load(DTW_distance_matrix_path)\n",
    "Cluster_8_ID_1 = Best_label_cluster[1]\n",
    "print(len(Cluster_8_ID_1))\n",
    "print(DTW_distance_matrix.shape)\n",
    "feature_true_id_prediction_path = \"./data/feature_true_id_prediction.pkl\"\n",
    "feature_true_id_prediction = np.load(feature_true_id_prediction_path, allow_pickle=True)\n",
    "fi_name_list = list(feature_true_id_prediction.keys())\n",
    "print(len(fi_name_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3f4fe42277042719f669cd0aeab047c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\n",
      "文件写入成功！cluster_8_id_1_result\n",
      "特定feature 写入成功！\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "Cluster_8_ID_distance = np.zeros((len(Cluster_8_ID_1), len(Cluster_8_ID_1)))\n",
    "for i, f_id_a in tqdm(enumerate(Cluster_8_ID_1)):\n",
    "    for j in range(i+1):\n",
    "        f_id_b = Cluster_8_ID_1[j]\n",
    "        index_a = fi_name_list.index(f_id_a)\n",
    "        index_b = fi_name_list.index(f_id_b)\n",
    "        score = DTW_distance_matrix[index_a, index_b]\n",
    "        Cluster_8_ID_distance[i][j] = score\n",
    "        Cluster_8_ID_distance[j][i] = score\n",
    "Cluster_8_ID_1_result = {\"fi_id_list\":Cluster_8_ID_1,\n",
    "                         \"DTW_distance_matrix\":Cluster_8_ID_distance\n",
    "                         }\n",
    "save_path = \"./processing/Cluster_8_ID_1__fid_list_distance.pkl\"\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(Cluster_8_ID_1_result, f)\n",
    "    print(\"文件写入成功！cluster_8_id_1_result\")\n",
    "\n",
    "save_path = \"./processing/feature_true_id_prediction_cluster_8_1.pkl\"\n",
    "feature_true_id_prediction_cluster_8_1 = {}\n",
    "for f_id in Cluster_8_ID_1:\n",
    "    feature_true_id_prediction_cluster_8_1[f_id] = feature_true_id_prediction[f_id]\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(feature_true_id_prediction_cluster_8_1, f)\n",
    "    print(\"特定feature 写入成功！\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(score_similarity_DTW.shape)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ching",
   "language": "python",
   "display_name": "ching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}