{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "this is test file!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import re\n",
    "from dtw import dtw\n",
    "from tqdm.notebook import tqdm\n",
    "print(\"this is test file!\")\n",
    "import seaborn as sns \n",
    "from sklearn.cluster import SpectralClustering\n",
    "import pickle\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.根据相似矩阵进行谱聚类的计算 "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(4224, 4224)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def normalized_matrix(data):\n",
    "    data_min = np.min(data.flatten())\n",
    "    data_max = np.max(data.flatten())\n",
    "    nor_data = (data-data_min) /(data_max-data_min)\n",
    "    return nor_data\n",
    "\n",
    "path = \"./processing/DTW_similarity_matrix.npy\"\n",
    "DTW_similarity = np.load(path, allow_pickle=True)\n",
    "# print(DTW_similarity)\n",
    "nor_data = normalized_matrix(DTW_similarity)\n",
    "print(nor_data.shape)\n",
    "DTW_similarity = nor_data\n",
    "# print(nor_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.对相似度进行正则化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=99.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d48b18c2cfb475bad267c340a7e79d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 根据邻接矩阵计算谱聚类的结果\n",
    "\n",
    "save_path = \"./processing/DTW_similarity_matrix_clustering.pkl\"\n",
    "\n",
    "cluster_result = {}\n",
    "rang_clustering = (2, 100)\n",
    "for i in tqdm(range(rang_clustering[0], rang_clustering[1]+1)):\n",
    "    n_clusters = i\n",
    "    seeg_clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0, affinity = \"precomputed\").fit_predict(DTW_similarity)\n",
    "#     print(seeg_clustering)\n",
    "    id_key = \"cluster_{}\".format(i)\n",
    "    cluster_result[id_key] = seeg_clustering\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(cluster_result, f)\n",
    "    print(\"Saving result: {}\".format(save_path))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 根据谱聚类的结果进行聚类效果的分析"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:42:51.048236Z",
     "start_time": "2020-01-03T08:42:51.023774Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(cluster_result['cluster_7'])\n",
    "cluster_result = np.load(\"./processing/DTW_similarity_matrix_clustering.pkl\", allow_pickle=True)\n",
    "path_data = \"./data/BDP_val_prediction.pkl\"\n",
    "feature_val_prediction = np.load(path_data, allow_pickle=True)\n",
    "print(feature_val_prediction)\n",
    "count_ground = [0,0]\n",
    "count_pre = [0,0]\n",
    "filter_feature_val_prediction ={}\n",
    "for id, d in feature_val_prediction.items():\n",
    "    count_ground[d[\"ground truth\"]] += 1\n",
    "    count_pre[d[\"prediction\"]] += 1 \n",
    "    if d[\"ground truth\"] == d[\"prediction\"]:\n",
    "        filter_feature_val_prediction[id] = d\n",
    "print(\"原本的数据分布！\")\n",
    "print(\"ground_truth:{}  prediction:{}\".format(count_ground, count_pre))\n",
    "\n",
    "count_ground = [0,0]\n",
    "count_pre = [0,0]\n",
    "print(\"预测结果的数据分布！\")\n",
    "for id, d in filter_feature_val_prediction.items():\n",
    "    count_ground[d[\"ground truth\"]] += 1\n",
    "    count_pre[d[\"prediction\"]] += 1                    \n",
    "print(\"ground_truth:{}  prediction:{}\".format(count_ground, count_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:42:53.806651Z",
     "start_time": "2020-01-03T08:42:53.748842Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(len(filter_feature_val_prediction))\n",
    "# print(filter_feature_val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for id, data in cluster_result.items():\n",
    "    cluster_data = data\n",
    "    print(dict(Counter(cluster_data)))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:42:58.800024Z",
     "start_time": "2020-01-03T08:42:57.484904Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "path_data = \"./data/feature_true_id_prediction.pkl\"\n",
    "feature_true_id_prediction = np.load(path_data, allow_pickle=True)\n",
    "feature_true_id_prediction_numpy = []\n",
    "for id, d in feature_true_id_prediction.items():\n",
    "    feature_true_id_prediction_numpy.append(d.tolist())\n",
    "# print(feature_true_id_prediction_numpy)\n",
    "for n_clusters, d in cluster_result.items(): \n",
    "    labels = d\n",
    "    score = davies_bouldin_score(feature_true_id_prediction_numpy, labels)\n",
    "    print(\"{}:{}\".format(n_clusters, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 选择表现性能最好的簇"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:43:03.149543Z",
     "start_time": "2020-01-03T08:43:03.142293Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 根据评分选择最好的簇 DBI 得分最低的簇为 cluster=7\n",
    "cluster_name = \"cluster_7\"\n",
    "label_list = cluster_result[\"cluster_7\"]\n",
    "wave_clusters = {}\n",
    "wave_clusters_id = {}\n",
    "\n",
    "# clusters feeature {cluster id :(raw data, raw data id)}\n",
    "for i ,(id, d)  in enumerate(feature_true_id_prediction.items()):\n",
    "    label = label_list[i]\n",
    "    if label not in wave_clusters.keys():\n",
    "        wave_clusters[label] = []\n",
    "        wave_clusters_id[label] = []\n",
    "    wave_clusters[label].append((d, id))\n",
    "    wave_clusters_id[label].append(id)\n",
    "# print(wave_clusters)\n",
    "with open(\"./processing/wave_clusters_id_feature_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(wave_clusters, f)\n",
    "    print(\"Cluster ID-feature data finished!\")\n",
    "with open(\"./processing/Best_label_cluster.pkl\", 'wb') as f:\n",
    "    pickle.dump(wave_clusters_id, f)\n",
    "    print(\"簇滤波id序列构建完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:43:09.323866Z",
     "start_time": "2020-01-03T08:43:09.316920Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def similarity_DTW(s1, s2):\n",
    "    ratio = 50 # 设定的放缩系数，避免数据的相似度过于集中\n",
    "    euclidean_norm = lambda x, y: np.abs(ratio * (x - y))\n",
    "    d, cost_matrix, acc_cost_matrix, path = dtw(s1, s2, dist=euclidean_norm)\n",
    "    score = 1 - np.tanh(d)  # 相似度的评分【0,1】 0： 完全不同， 1： 完全相同\n",
    "    return score\n",
    "\n",
    "def get_top_score_series(series_dict, top_n = 5):\n",
    "    scores = []\n",
    "    raw_data_series = [x[0] for x in series_dict]\n",
    "    for s_a, feature_id in tqdm(series_dict):\n",
    "        score = 0\n",
    "        for s_b in raw_data_series:\n",
    "            score += similarity_DTW(s_a, s_b)\n",
    "        avg_score = score / len(series_dict)\n",
    "        _ = (feature_id, score)\n",
    "        scores.append(_)\n",
    "    result = sorted(scores, key=lambda x:-x[1])\n",
    "    result = result[:top_n]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T08:43:13.833956Z",
     "start_time": "2020-01-03T08:43:13.789393Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# DBA\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "def sum_of_squares(s,series,cost_mat,delta_mat):\n",
    "    return sum(map(lambda t:squared_DTW(s,t,cost_mat,delta_mat),series))\n",
    "\n",
    "def approximate_medoid_index(series,cost_mat,delta_mat):\n",
    "    if len(series)<=50:\n",
    "        indices = range(0,len(series))\n",
    "    else:\n",
    "        indices = np.random.choice(range(0,len(series)),50,replace=False)\n",
    "\n",
    "    medoid_ind = -1\n",
    "    best_ss = 1e20\n",
    "    for index_candidate in indices:\n",
    "        candidate = series[index_candidate]\n",
    "        ss = sum_of_squares(candidate,series,cost_mat,delta_mat)\n",
    "        if(medoid_ind==-1 or ss<best_ss):\n",
    "            best_ss = ss\n",
    "            medoid_ind = index_candidate\n",
    "    return medoid_ind\n",
    "\n",
    "def squared_DTW(s,t,cost_mat,delta_mat):\n",
    "    s_len = len(s)\n",
    "    t_len = len(t)\n",
    "    length = len(s)\n",
    "    fill_delta_mat_dtw(s, t, delta_mat)\n",
    "    cost_mat[0, 0] = delta_mat[0, 0]\n",
    "    for i in range(1, s_len):\n",
    "        cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "\n",
    "    for j in range(1, t_len):\n",
    "        cost_mat[0, j] = cost_mat[0, j-1]+delta_mat[0, j]\n",
    "\n",
    "    for i in range(1, s_len):\n",
    "        for j in range(1, t_len):\n",
    "            diag,left,top =cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j]\n",
    "            if(diag <=left):\n",
    "                if(diag<=top):\n",
    "                    res = diag\n",
    "                else:\n",
    "                    res = top\n",
    "            else:\n",
    "                if(left<=top):\n",
    "                    res = left\n",
    "                else:\n",
    "                    res = top\n",
    "            cost_mat[i, j] = res+delta_mat[i, j]\n",
    "    return cost_mat[s_len-1,t_len-1]\n",
    "\n",
    "def fill_delta_mat_dtw(center, s, delta_mat):\n",
    "    slim = delta_mat[:len(center),:len(s)]\n",
    "    np.subtract.outer(center, s,out=slim)\n",
    "    np.square(slim, out=slim)\n",
    "\n",
    "def DBA_update(center, series, cost_mat, path_mat, delta_mat):\n",
    "    options_argmin = [(-1, -1), (0, -1), (-1, 0)]\n",
    "    updated_center = np.zeros(center.shape)\n",
    "    n_elements = np.array(np.zeros(center.shape), dtype=int)\n",
    "    center_length = len(center)\n",
    "    for s in series:\n",
    "        s_len = len(s)\n",
    "        fill_delta_mat_dtw(center, s, delta_mat)\n",
    "        cost_mat[0, 0] = delta_mat[0, 0]\n",
    "        path_mat[0, 0] = -1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "            path_mat[i, 0] = 2\n",
    "\n",
    "        for j in range(1, s_len):\n",
    "            cost_mat[0, j] = cost_mat[0, j-1]+delta_mat[0, j]\n",
    "            path_mat[0, j] = 1\n",
    "\n",
    "        for i in range(1, center_length):\n",
    "            for j in range(1, s_len):\n",
    "                diag,left,top =cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j]\n",
    "                if(diag <=left):\n",
    "                    if(diag<=top):\n",
    "                        res = diag\n",
    "                        path_mat[i,j] = 0\n",
    "                    else:\n",
    "                        res = top\n",
    "                        path_mat[i,j] = 2\n",
    "                else:\n",
    "                    if(left<=top):\n",
    "                        res = left\n",
    "                        path_mat[i,j] = 1\n",
    "                    else:\n",
    "                        res = top\n",
    "                        path_mat[i,j] = 2\n",
    "\n",
    "                cost_mat[i, j] = res+delta_mat[i, j]\n",
    "\n",
    "        i = center_length-1\n",
    "        j = s_len-1\n",
    "\n",
    "        while(path_mat[i, j] != -1):\n",
    "            updated_center[i] += s[j]\n",
    "            n_elements[i] += 1\n",
    "            move = options_argmin[path_mat[i, j]]\n",
    "            i += move[0]\n",
    "            j += move[1]\n",
    "        assert(i == 0 and j == 0)\n",
    "        updated_center[i] += s[j]\n",
    "        n_elements[i] += 1\n",
    "\n",
    "    return np.divide(updated_center, n_elements)\n",
    "def performDBA(series, n_iterations=5):\n",
    "    n_series = len(series)\n",
    "    max_length = reduce(max, map(len, series))\n",
    "\n",
    "    cost_mat = np.zeros((max_length, max_length))\n",
    "    delta_mat = np.zeros((max_length, max_length))\n",
    "    path_mat = np.zeros((max_length, max_length), dtype=np.int8)\n",
    "\n",
    "    medoid_ind = approximate_medoid_index(series,cost_mat,delta_mat)\n",
    "    center = series[medoid_ind]\n",
    "\n",
    "    for i in range(0,n_iterations):\n",
    "        center = DBA_update(center,\n",
    "                            series, cost_mat, path_mat, delta_mat)\n",
    "\n",
    "    return center "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-03T08:43:24.018Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.Clustering HeatMap\n",
    "DBA_id_wave = {}\n",
    "for cluster_id, data in tqdm(wave_clusters.items()):\n",
    "    series = []\n",
    "    for d, id in data:\n",
    "        series.append(d)\n",
    "    s_DBA = performDBA(series)\n",
    "    DBA_id_wave[cluster_id] = s_DBA\n",
    "\n",
    "with open(\"./processing/DBA_wave.pkl\", 'wb') as f:\n",
    "    pickle.dump(DBA_id_wave, f)\n",
    "    print(\"Saving Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ching",
   "language": "python",
   "name": "ching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "ctrl-shift-e"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}